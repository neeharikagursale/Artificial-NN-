# -*- coding: utf-8 -*-
"""Assignmnment_neural Networks_Forestfire.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15SvbtGjtixdwXhNltwp0sRjORjHXT3Uz
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from keras.models import Sequential
from keras.layers import Dense, Activation,Layer,Lambda

forestfires = pd.read_csv("forestfires.csv")
forestfires.head()

forestfires.drop(["month","day"],axis=1,inplace = True)

forestfires["size_category"].value_counts()

forestfires.describe()

forestfires.columns

plt.hist((forestfires.area))

forestfires.hist()

forestfires.loc[forestfires["size_category"]=='small','size_category']=0
forestfires.loc[forestfires["size_category"]=='large','size_category']=1
forestfires["size_category"].value_counts()

def norm_func(i):
     x = (i-i.min())/(i.max()-i.min())
     return (x)

pred = forestfires.iloc[:,0:28]
target = forestfires.iloc[:,28]

pred1 = norm_func(pred)

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test= train_test_split(predictors1,target, test_size=0.3,stratify = target)

def prep_model(hidden_dim):
    model = Sequential()
    for i in range(1,len(hidden_dim)-1):
        if (i==1):
            model.add(Dense(hidden_dim[i],input_dim=hidden_dim[0],activation="relu"))
        else:
            model.add(Dense(hidden_dim[i],activation="relu"))
    model.add(Dense(hidden_dim[-1],kernel_initializer="normal",activation="sigmoid"))
    model.compile(loss="binary_crossentropy",optimizer = "rmsprop",metrics = ["accuracy"])
    return model

x_train = np.asarray(x_train).astype('float32')
y_train = np.asarray(y_train).astype('float32')

first_model = prep_model([28,50,40,20,1])
first_model.fit(np.array(x_train),np.array(y_train),epochs=500)
pred_train = first_model.predict(np.array(x_train))

pred_train = pd.Series([i[0] for i in pred_train])

size = ["small","large"]
pred_train_class = pd.Series(["small"]*361)
pred_train_class[[i>0.5 for i in pred_train]]= "large"

forestfires1=pd.DataFrame(x_train, columns=['FFMC', 'DMC', 'DC', 'ISI', 'temp', 'RH', 'wind', 'rain', 'area',
       'dayfri', 'daymon', 'daysat', 'daysun', 'daythu', 'daytue', 'daywed',
       'monthapr', 'monthaug', 'monthdec', 'monthfeb', 'monthjan', 'monthjul',
       'monthjun', 'monthmar', 'monthmay', 'monthnov', 'monthoct', 'monthsep']) 
forestfires1

forestfires2=pd.DataFrame(y_train, columns=['size_category']) 
forestfires2

train = pd.concat([forestfires1,forestfires2],axis=1)
train["size_category"].value_counts()

from sklearn.metrics import confusion_matrix
confusion_matrix(pred_train_class,train["original_class"])

pred_test = first_model.predict(np.array(x_test))
pred_test = pd.Series([i[0] for i in pred_test])
pred_test_class = pd.Series(["small"]*156)
pred_test_class[[i>0.5 for i in pred_test]] = "large"
test =pd.concat([x_test,y_test],axis=1)
test["original_class"]="small"
test.loc[test["size_category"]==1,"original_class"] = "large"

test["original_class"].value_counts()
confusion_matrix(pred_test_class,test["original_class"])

